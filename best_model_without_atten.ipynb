{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-04T09:43:50.322100Z"
        },
        "id": "FsMRpLJt_egZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# DL Assignment 3\n",
        "# version 19.\n",
        "# code to run best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDghhjha-xUK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADfNyi1sB9L3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Agml7HAllJ",
        "outputId": "5907f690-6e4b-473e-8dfc-b0fab9c372be",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "299AqvvaEdkf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# path = '/kaggle/input/marathi/mar_train.csv'\n",
        "# path_val = '/kaggle/input/marathi/mar_valid.csv'\n",
        "# path_test = '/kaggle/input/marathi/mar_test.csv'\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv'\n",
        "path_val = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv'\n",
        "path_test = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtpQ9UGxFhkU",
        "outputId": "f1e70afc-85a2-4816-94cd-00e207f0d9ac",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                 1\n",
            "50000  audhogikikaranamule   औधोगिकीकरणामुळे\n",
            "50001     anyayaviruddhahi  अन्यायाविरुद्धही\n",
            "50002              fairade            फैराडे\n",
            "50003          inputmadhye        इनपुटमध्ये\n",
            "50004      charitranmadhil      चरित्रांमधील\n",
            "...                    ...               ...\n",
            "51195           chikateche           चिकटेचे\n",
            "51196     anubhavanyachahi     अनुभवण्याचाही\n",
            "51197            andhapuri          अंधापुरी\n",
            "51198           ghadamodee           घडामोडी\n",
            "51199         atiprachalit        अतिप्रचलित\n",
            "\n",
            "[1200 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(path , header = None)\n",
        "df_val = pd.read_csv(path_val , header = None)\n",
        "df_test = pd.read_csv(path_test , header = None)\n",
        "english_words_val = df_val[0]\n",
        "marathi_words_val = df_val[1]\n",
        "english_words_test = df_test[0]\n",
        "marathi_words_test = df_test[1]\n",
        "english_words = df[0]\n",
        "marathi_words = df[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtlfObKubBNq",
        "outputId": "6f0701f1-4823-47fc-b128-56c9446fd71a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऍ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
            "28\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "# creating list of charecters in both languages\n",
        "\n",
        "english_char_list = []\n",
        "max_length_word_english = -1\n",
        "for word in english_words:\n",
        "  max_length_word_english = max(max_length_word_english,len(word)) \n",
        "  for char in word :\n",
        "    english_char_list.append(char);\n",
        "english_char_list = list(set(english_char_list))\n",
        "english_char_list.sort()\n",
        "\n",
        "marathi_char_list = []\n",
        "max_length_word_marathi = -1\n",
        "for word in marathi_words:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
        "  for char in word :\n",
        "    marathi_char_list.append(char);\n",
        "marathi_char_list = list(set(marathi_char_list))\n",
        "marathi_char_list.sort()\n",
        "\n",
        "\n",
        "# finding out the maximum size word for english and marathi from validation and test data.\n",
        "for word in english_words_val:\n",
        "  max_length_word_english = max(max_length_word_english,len(word))\n",
        "for word in english_words_test:\n",
        "  max_length_word_english = max(max_length_word_english,len(word)) \n",
        "for word in marathi_words_val:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
        "for word in marathi_words_test:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdcqBaU70W3v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# english word to vector size = 27 ie. max_length_word_english\n",
        "# marathi word to vector size = 20 ie. max_length_word_marathi\n",
        "# for one word.\n",
        "def word2vec(word, lang):\n",
        "  vec = []\n",
        "  if(lang == \"english\"):\n",
        "    vec.append(len(english_char_list) + 1)\n",
        "    for char in word:\n",
        "      for i in range(len(english_char_list)):\n",
        "        if(english_char_list[i] == char):\n",
        "          vec.append(i+1)\n",
        "    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n",
        "        vec.append(0)\n",
        "    vec.append(0)\n",
        "  else :\n",
        "    vec.append(len(marathi_char_list) + 1)\n",
        "    for char in word:\n",
        "      for i in range(len(marathi_char_list)):\n",
        "        if( marathi_char_list[i] == char):\n",
        "          vec.append(i+1)\n",
        "    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n",
        "        vec.append(0)\n",
        "    vec.append(0)\n",
        "  return(vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heu_03Y3332P",
        "outputId": "bd542307-bcad-4812-9711-0bf468c89a20",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "हरिहरक्षेत्र\n",
            "[64, 49, 42, 52, 49, 42, 17, 63, 47, 58, 31, 63, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "vec = word2vec(marathi_words[10],\"marathi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRObgwk5pcEz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# creating matrix of representation for whole words of english and marathi.\n",
        "\n",
        "def ip_matrix_construct(words, lang):\n",
        "  ans = []\n",
        "  for word in words:\n",
        "    ans.append(word2vec(word, lang))\n",
        "  return(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FgS76C6rluA",
        "outputId": "ef164c52-28ad-470c-f430-b4ab0b25c91f",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51200\n",
            "51200\n",
            "30\n",
            "22\n"
          ]
        }
      ],
      "source": [
        "# calculated representations of whole english and marathi words in variables english and marathi matrix.\n",
        "english_matrix = ip_matrix_construct(english_words, \"english\")\n",
        "marathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n",
        "english_matrix = torch.tensor(english_matrix)\n",
        "marathi_matrix = torch.tensor(marathi_matrix)\n",
        "\n",
        "english_matrix_val = ip_matrix_construct(english_words_val, \"english\")\n",
        "marathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\n",
        "english_matrix_val = torch.tensor(english_matrix_val)\n",
        "marathi_matrix_val = torch.tensor(marathi_matrix_val)\n",
        "english_matrix_test = ip_matrix_construct(english_words_test, \"english\")\n",
        "marathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\n",
        "english_matrix_test = torch.tensor(english_matrix_test)\n",
        "marathi_matrix_test = torch.tensor(marathi_matrix_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvjQGsLrsBJZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size, embedding_size, hidden_size, enc_layers, p, cell_type, bidirectional):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.enc_layers = enc_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.cell_type = cell_type\n",
        "    self.bidirectional = bidirectional\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if(cell_type == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
        "    if(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
        "    if(cell_type == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    if(self.cell_type == \"GRU\"):\n",
        "      output, hidden = self.gru(embedding)\n",
        "    if(self.cell_type == \"RNN\"):\n",
        "      output, hidden = self.rnn(embedding)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "      outputs, (hidden,cell) = self.lstm(embedding)\n",
        "      return outputs, hidden, cell\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nea9Nz5E-xUP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dec_layers = dec_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if(cell_type == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout = p)\n",
        "    if(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout = p)\n",
        "    if(cell_type == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout = p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n",
        "  \n",
        "  def forward(self,x,output, hidden, cell = 0):\n",
        "    x = x.unsqueeze(0).int()\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    if(self.cell_type == \"GRU\"):\n",
        "        outputs, hidden = self.gru(embedding, hidden)\n",
        "    if(self.cell_type == \"RNN\"):\n",
        "        outputs, hidden = self.rnn(embedding, hidden)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "    # shape of outputs: (1, N, hidden_size)\n",
        "    predictions = self.fc(outputs)\n",
        "    # shape of predictions: (1, N, length_of_vocab)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    # shape of predictions: (N, length_of_vocab)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "        return predictions, hidden, cell\n",
        "    return predictions, hidden\n",
        "\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmqgOzhw0t37"
      },
      "outputs": [],
      "source": [
        "class Atten_decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, bidirectional):\n",
        "    super(Atten_decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.max_length = len(english_matrix[0])  \n",
        "    self.dec_layers = dec_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if(cell_type == \"GRU\"):\n",
        "      self.gru = nn.GRU(hidden_size, hidden_size, dec_layers, dropout = p)\n",
        "    if(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(hidden_size, hidden_size, dec_layers, dropout = p)\n",
        "    if(cell_type == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(hidden_size, hidden_size, dec_layers, dropout = p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n",
        "    self.attn = nn.Linear(hidden_size+embedding_size, self.max_length)\n",
        "    if(bidirectional):\n",
        "      self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size)\n",
        "    else :\n",
        "      self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
        "\n",
        "  def forward(self, x,output, hidden, cell = 0):\n",
        "    x = x.unsqueeze(0)\n",
        "    output=output.permute(1,0,2)\n",
        "    embedded = self.embedding(x)\n",
        "    embedded = self.dropout(embedded)\n",
        "    attn_weights = F.softmax(self.attn(torch.cat((embedded[0],hidden[0]), 1)), dim = 1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(1),output)\n",
        "    attn_applied = attn_applied.squeeze(1)\n",
        "    op = torch.cat((embedded[0], attn_applied), 1)\n",
        "\n",
        "    op = self.attn_combine(op).unsqueeze(0)\n",
        "    op = F.relu(op)\n",
        "    if(self.cell_type == \"GRU\"):\n",
        "        outputs, hidden = self.gru(op, hidden)\n",
        "    if(self.cell_type == \"RNN\"):\n",
        "        outputs, hidden = self.rnn(op, hidden)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "        outputs, (hidden, cell) = self.lstm(op, (hidden, cell))\n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "        return predictions, hidden, cell\n",
        "    return predictions, hidden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkWSEAca-Okj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, cell_type, bidirectional, enc_layers, dec_layers):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "        self.enc_layers = enc_layers\n",
        "        self.dec_layers = dec_layers\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(marathi_char_list) + 2  \n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "        if(self.cell_type == \"LSTM\"):\n",
        "            encoder_output, hidden, cell = self.encoder(source)\n",
        "        else:\n",
        "            encoder_output, hidden = self.encoder(source)\n",
        "        if(self.enc_layers != self.dec_layers or self.bidirectional == True):\n",
        "          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n",
        "          hidden = hidden.repeat(self.dec_layers,1,1)\n",
        "          if(self.cell_type == \"LSTM\"):\n",
        "              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n",
        "              cell = cell.repeat(self.dec_layers,1,1)\n",
        "        \n",
        "        x = target[0]\n",
        "    \n",
        "        for t in range(1, target_len):\n",
        "            if(self.cell_type == \"LSTM\"):\n",
        "                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n",
        "            else :\n",
        "                output, hidden = self.decoder(x, encoder_output, hidden)\n",
        "            outputs[t] = output\n",
        "\n",
        "            best_guess = output.argmax(1)\n",
        "\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "            \n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYajaq47-xUQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size):\n",
        "    correct_count = 0\n",
        "    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        output = model.forward(inp_data.T, target.T, 0)\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        output = output.T\n",
        "        for i in range(batch_size):\n",
        "            if(torch.equal(output[i][1:],target[i][1:])):\n",
        "                correct_count += 1\n",
        "    accuracy = correct_count * 100 / len(english_matrix)\n",
        "    return accuracy\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating list of expected marathi word and predicted marathi word.\n",
        "predictions_vanilla_train = []\n",
        "predictions_vanilla_val = []\n",
        "predictions_vanilla_test = []\n",
        "def matrix_to_words(model, english_matrix, marathi_matrix, batch_size, data_type):\n",
        "  for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        output = model.forward(inp_data.T, target.T, 0)\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        output = output.T\n",
        "        for i in range(len(target)):\n",
        "          target_word = target[i]\n",
        "          output_word = output[i]\n",
        "          word1 = \"\"\n",
        "          word2 = \"\"\n",
        "          for j in range(len(target_word)):\n",
        "            if(target_word[j]>0 and target_word[j]<64):\n",
        "              word1 += marathi_char_list[target_word[j] - 1]\n",
        "          for j in range(len(output_word)):\n",
        "            if(output_word[j]>0 and output_word[j]<64):\n",
        "              word2 += marathi_char_list[output_word[j] - 1]\n",
        "          temp = [word1, word2]\n",
        "          if(data_type == \"train\"):\n",
        "            predictions_vanilla_train.append(temp)\n",
        "          if(data_type == \"validation\"):\n",
        "            predictions_vanilla_val.append(temp)\n",
        "          if(data_type == \"test\"):\n",
        "            predictions_vanilla_test.append(temp)"
      ],
      "metadata": {
        "id": "Vg6VQCWWzhoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QCnSmaTMRSR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention):\n",
        "  learning_rate = 1e-3\n",
        "  num_epochs = 20\n",
        "  input_size_encoder = len(english_char_list) + 2  \n",
        "  input_size_decoder = len(marathi_char_list) + 2  \n",
        "  output_size        = len(marathi_char_list) + 2  \n",
        "\n",
        "  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, enc_layers, enc_dropout, cell_type,bidirectional).to(device)\n",
        "  if(attention):\n",
        "    decoder_net = Atten_decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type, bidirectional).to(device)\n",
        "  else:\n",
        "    decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type).to(device)\n",
        "\n",
        "  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, enc_layers, dec_layers).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  pad_idx = len(marathi_char_list) + 1  # 64 # pading index for marathi\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(\"epoch = \",epoch)\n",
        "\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      step = 0\n",
        "      for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "\n",
        "          inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "          target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "          target = target.T\n",
        "          output = model(inp_data.T, target)\n",
        "\n",
        "          output = output[1:].reshape(-1, output.shape[2])\n",
        "          target = target[1:].reshape(-1)\n",
        "          optimizer.zero_grad()\n",
        "          loss = criterion(output, target)\n",
        "          total_loss += loss\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          step += 1\n",
        "      print(\"total loss = \",total_loss / step)\n",
        "      training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size)\n",
        "      print(\"Training Accuracy = \", training_accuracy)\n",
        "      val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch, batch_size)\n",
        "      print(\"Validation accuracy = \",val_accuracy)\n",
        "      test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch, batch_size)\n",
        "      print(\"Test accuracy = \", test_accuracy)\n",
        "      if(epoch > 10 and training_accuracy < 10):\n",
        "        return\n",
        "      if(epoch > 5 and training_accuracy < 1):\n",
        "        return\n",
        "  matrix_to_words(model, english_matrix, marathi_matrix, batch_size, \"train\")\n",
        "  print(\"train done\")\n",
        "  matrix_to_words(model, english_matrix_val, marathi_matrix_val, batch_size, \"validation\")\n",
        "  print(\"val done\")\n",
        "  matrix_to_words(model, english_matrix_test, marathi_matrix_test, batch_size, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkkdB4_mxLWV",
        "outputId": "b72ad08d-3643-4cb1-c283-cb55a2ad4700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  0\n",
            "total loss =  tensor(1.6752, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  0.0\n",
            "Validation accuracy =  0.0244140625\n",
            "Test accuracy =  0.0244140625\n",
            "epoch =  1\n",
            "total loss =  tensor(1.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  6.099609375\n",
            "Validation accuracy =  9.9853515625\n",
            "Test accuracy =  8.642578125\n",
            "epoch =  2\n",
            "total loss =  tensor(0.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  17.62890625\n",
            "Validation accuracy =  20.458984375\n",
            "Test accuracy =  18.26171875\n",
            "epoch =  3\n",
            "total loss =  tensor(0.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  27.26953125\n",
            "Validation accuracy =  26.0986328125\n",
            "Test accuracy =  23.5107421875\n",
            "epoch =  4\n",
            "total loss =  tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  33.462890625\n",
            "Validation accuracy =  28.80859375\n",
            "Test accuracy =  25.48828125\n",
            "epoch =  5\n",
            "total loss =  tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  42.15625\n",
            "Validation accuracy =  36.181640625\n",
            "Test accuracy =  30.810546875\n",
            "epoch =  6\n",
            "total loss =  tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  45.77734375\n",
            "Validation accuracy =  36.4990234375\n",
            "Test accuracy =  31.1767578125\n",
            "epoch =  7\n",
            "total loss =  tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  49.392578125\n",
            "Validation accuracy =  37.4755859375\n",
            "Test accuracy =  31.640625\n",
            "epoch =  8\n",
            "total loss =  tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  53.015625\n",
            "Validation accuracy =  38.3544921875\n",
            "Test accuracy =  33.59375\n",
            "epoch =  9\n",
            "total loss =  tensor(0.1661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  57.49609375\n",
            "Validation accuracy =  40.91796875\n",
            "Test accuracy =  35.8154296875\n",
            "epoch =  10\n",
            "total loss =  tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  60.568359375\n",
            "Validation accuracy =  41.357421875\n",
            "Test accuracy =  36.669921875\n",
            "epoch =  11\n",
            "total loss =  tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  62.443359375\n",
            "Validation accuracy =  42.3828125\n",
            "Test accuracy =  37.59765625\n",
            "epoch =  12\n",
            "total loss =  tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  62.27734375\n",
            "Validation accuracy =  40.91796875\n",
            "Test accuracy =  37.20703125\n",
            "epoch =  13\n",
            "total loss =  tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  63.78515625\n",
            "Validation accuracy =  40.869140625\n",
            "Test accuracy =  37.7197265625\n",
            "epoch =  14\n",
            "total loss =  tensor(0.1142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  67.15234375\n",
            "Validation accuracy =  41.845703125\n",
            "Test accuracy =  36.1572265625\n",
            "epoch =  15\n",
            "total loss =  tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  67.400390625\n",
            "Validation accuracy =  41.162109375\n",
            "Test accuracy =  36.4990234375\n",
            "epoch =  16\n",
            "total loss =  tensor(0.1094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  69.322265625\n",
            "Validation accuracy =  42.0654296875\n",
            "Test accuracy =  37.5732421875\n",
            "epoch =  17\n",
            "total loss =  tensor(0.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  70.701171875\n",
            "Validation accuracy =  42.578125\n",
            "Test accuracy =  37.0361328125\n",
            "epoch =  18\n",
            "total loss =  tensor(0.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  71.763671875\n",
            "Validation accuracy =  42.1875\n",
            "Test accuracy =  37.5\n",
            "epoch =  19\n",
            "total loss =  tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  72.244140625\n",
            "Validation accuracy =  42.7490234375\n",
            "Test accuracy =  36.42578125\n",
            "train done\n",
            "val done\n"
          ]
        }
      ],
      "source": [
        "cell_type = \"GRU\"\n",
        "bidirectional = False\n",
        "enc_layers = 5\n",
        "dec_layers = 5\n",
        "batch_size = 256\n",
        "embedding_size = 256\n",
        "hidden_size = 512\n",
        "enc_dropout = 0.2\n",
        "dec_dropout = 0.2\n",
        "attention = False\n",
        "\n",
        "\n",
        "neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating csv file of predictions\n",
        "filename_train  = 'predictions_vanilla_train.csv'\n",
        "filename_val = 'predictions_vanilla_val.csv'\n",
        "filename_test = 'predictions_vanilla_test.csv'\n",
        "\n",
        "with open(filename_train, 'w', newline='') as file:\n",
        "    writer = csv.writer(file, quoting=csv.QUOTE_NONE)\n",
        "    writer.writerows(predictions_vanilla_train)\n",
        "\n",
        "print(f'CSV file \"{filename_train}\" has been created.')\n",
        "\n",
        "\n",
        "with open(filename_val, 'w', newline='') as file:\n",
        "    writer = csv.writer(file, quoting=csv.QUOTE_NONE)\n",
        "    writer.writerows(predictions_vanilla_val)\n",
        "\n",
        "print(f'CSV file \"{filename_val}\" has been created.')\n",
        "\n",
        "\n",
        "with open(filename_test, 'w', newline='') as file:\n",
        "    writer = csv.writer(file, quoting=csv.QUOTE_NONE)\n",
        "    writer.writerows(predictions_vanilla_test)\n",
        "\n",
        "print(f'CSV file \"{filename_test}\" has been created.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIS3GbEF5dsP",
        "outputId": "2f4b1594-3f7a-4502-f7e5-994c753b7a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file \"predictions_vanilla_train.csv\" has been created.\n",
            "CSV file \"predictions_vanilla_val.csv\" has been created.\n",
            "CSV file \"predictions_vanilla_test.csv\" has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qwOMgXc-xUR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67svBk48GAaX",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW22hUA2vTpV",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMyJeinM-xUS",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9sr6TtgPdmn",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crRv0WD-Hu6V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyTr7QZKMqQG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1reXcQN1-xUT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrNT-rKM-xUT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPoWLZG3-xUT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}