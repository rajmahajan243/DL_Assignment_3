<<<<<<< HEAD
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-04T09:43:50.322100Z"},"id":"FsMRpLJt_egZ","trusted":true},"outputs":[],"source":["# DL Assignment 3\n","# version 19.\n","# project name changed to final project name.\n","# added if condition for early stopping of less accuracy runs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDghhjha-xUK","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADfNyi1sB9L3","trusted":true},"outputs":[],"source":["import numpy as np\n","import math\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from keras.datasets import fashion_mnist\n","from sklearn.model_selection import train_test_split\n","\n","\n","# from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeBoqlNt-xUM","outputId":"abc676c5-4f51-4990-ec65-62947ad08b9b","trusted":true},"outputs":[],"source":["# device = \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtCn6lShP54p","trusted":true},"outputs":[],"source":["!pip install wandb\n","import wandb\n","wandb.login(key = \"c28eda24dacbd50a57332e445cfdfb2f4c16799c\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf7JgsItwUtY","trusted":true},"outputs":[],"source":["\n","# import wandb\n","wandb.init(project=\"DL_Assignment_3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6Agml7HAllJ","outputId":"969bc4ab-d668-488d-a48f-02587151f499","trusted":true},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"299AqvvaEdkf","trusted":true},"outputs":[],"source":["\n","path = '/kaggle/input/marathi/mar_train.csv'\n","path_val = '/kaggle/input/marathi/mar_valid.csv'\n","path_test = '/kaggle/input/marathi/mar_test.csv'\n","# path = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv'\n","# path_val = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv'\n","# path_test = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtpQ9UGxFhkU","outputId":"0e3e484e-b5c2-4081-e2a9-8555b59ba76d","trusted":true},"outputs":[],"source":["df = pd.read_csv(path , header = None)\n","# df.head()\n","df_val = pd.read_csv(path_val , header = None)\n","df_test = pd.read_csv(path_test , header = None)\n","english_words_val = df_val[0]\n","marathi_words_val = df_val[1]\n","english_words_test = df_test[0]\n","marathi_words_test = df_test[1]\n","english_words = df[0]\n","marathi_words = df[1]\n","# print(english_words)\n","# print(marathi_words)\n","print(df[50000:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtlfObKubBNq","outputId":"9d3d45e2-c809-49f0-a98b-407791473f74","trusted":true},"outputs":[],"source":["# creating list of charecters in both languages\n","\n","english_char_list = []\n","max_length_word_english = -1\n","for word in english_words:\n","  max_length_word_english = max(max_length_word_english,len(word)) \n","  for char in word :\n","    english_char_list.append(char);\n","english_char_list = list(set(english_char_list))\n","english_char_list.sort()\n","print(english_char_list)\n","\n","marathi_char_list = []\n","max_length_word_marathi = -1\n","for word in marathi_words:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","  for char in word :\n","    marathi_char_list.append(char);\n","marathi_char_list = list(set(marathi_char_list))\n","marathi_char_list.sort()\n","print(marathi_char_list)\n","\n","\n","# finding out the maximum size word for english and marathi from validation and test data.\n","for word in english_words_val:\n","  max_length_word_english = max(max_length_word_english,len(word))\n","for word in english_words_test:\n","  max_length_word_english = max(max_length_word_english,len(word)) \n","for word in marathi_words_val:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","for word in marathi_words_test:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","\n","print(max_length_word_english)\n","print(max_length_word_marathi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdcqBaU70W3v","trusted":true},"outputs":[],"source":["# english word to vector size = 27 ie. max_length_word_english\n","# marathi word to vector size = 20 ie. max_length_word_marathi\n","# for one word.\n","def word2vec(word, lang):\n","  vec = []\n","  if(lang == \"english\"):\n","    vec.append(len(english_char_list) + 1)\n","    for char in word:\n","      for i in range(len(english_char_list)):\n","        if(english_char_list[i] == char):\n","          vec.append(i+1)\n","    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n","        vec.append(0)\n","    vec.append(0)\n","  else :\n","    vec.append(len(marathi_char_list) + 1)\n","    for char in word:\n","      for i in range(len(marathi_char_list)):\n","        if( marathi_char_list[i] == char):\n","          vec.append(i+1)\n","    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n","        vec.append(0)\n","    vec.append(0)\n","  return(vec)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heu_03Y3332P","outputId":"399f1147-655c-4ff2-f9d9-224a5976b452","trusted":true},"outputs":[],"source":["vec = word2vec(marathi_words[10],\"marathi\")\n","print(marathi_words[10])\n","print(vec)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRObgwk5pcEz","trusted":true},"outputs":[],"source":["# creating matrix of representation for whole words of english and marathi.\n","\n","def ip_matrix_construct(words, lang):\n","  ans = []\n","  for word in words:\n","    ans.append(word2vec(word, lang))\n","  return(ans)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FgS76C6rluA","outputId":"beb676a0-b54d-478b-e437-7cb0c13341b5","trusted":true},"outputs":[],"source":["# calculated representations of whole english and marathi words in variables english and marathi matrix.\n","english_matrix = ip_matrix_construct(english_words, \"english\")\n","marathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n","print(len(english_matrix))\n","print(len(marathi_matrix))\n","english_matrix = torch.tensor(english_matrix)\n","marathi_matrix = torch.tensor(marathi_matrix)\n","\n","english_matrix_val = ip_matrix_construct(english_words_val, \"english\")\n","marathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\n","english_matrix_val = torch.tensor(english_matrix_val)\n","marathi_matrix_val = torch.tensor(marathi_matrix_val)\n","english_matrix_test = ip_matrix_construct(english_words_test, \"english\")\n","marathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\n","english_matrix_test = torch.tensor(english_matrix_test)\n","marathi_matrix_test = torch.tensor(marathi_matrix_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvjQGsLrsBJZ","trusted":true},"outputs":[],"source":["\n","class Encoder(nn.Module):\n","  def __init__(self,input_size, embedding_size, hidden_size, enc_layers, p, cell_type, bidirectional):\n","    super(Encoder,self).__init__()\n","    self.hidden_size = hidden_size\n","    self.enc_layers = enc_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.bidirectional = bidirectional\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","\n","  def forward(self, x):\n","    embedding = self.dropout(self.embedding(x))\n","    # embedding shape : (seq_length, N, embedding_size)\n","    if(self.cell_type == \"GRU\"):\n","      output, hidden = self.gru(embedding)\n","    if(self.cell_type == \"RNN\"):\n","      output, hidden = self.rnn(embedding)\n","    if(self.cell_type == \"LSTM\"):\n","      outputs, (hidden,cell) = self.lstm(embedding)\n","      return outputs, hidden, cell\n","    return output, hidden\n","\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nea9Nz5E-xUP","trusted":true},"outputs":[],"source":["\n","class Decoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type):\n","    super(Decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.dec_layers = dec_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout = p)\n","    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n","  \n","  def forward(self,x,output, hidden, cell = 0):\n","    # shape of x: (N) but we want (1,N)\n","    x = x.unsqueeze(0).int()\n","    embedding = self.dropout(self.embedding(x))\n","    # embedding shape : (1,N,embedding_size)\n","    if(self.cell_type == \"GRU\"):\n","        outputs, hidden = self.gru(embedding, hidden)\n","    if(self.cell_type == \"RNN\"):\n","        outputs, hidden = self.rnn(embedding, hidden)\n","    if(self.cell_type == \"LSTM\"):\n","        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n","    # shape of outputs: (1, N, hidden_size)\n","    predictions = self.fc(outputs)\n","    # shape of predictions: (1, N, length_of_vocab)\n","    predictions = predictions.squeeze(0)\n","    # shape of predictions: (N, length_of_vocab)\n","    if(self.cell_type == \"LSTM\"):\n","        return predictions, hidden, cell\n","    return predictions, hidden\n","\n","\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmqgOzhw0t37"},"outputs":[],"source":["class Atten_decoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, bidirectional):\n","    super(Atten_decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.max_length = len(english_matrix[0])  #30\n","    self.dec_layers = dec_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(hidden_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(hidden_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(hidden_size, hidden_size, dec_layers, dropout = p)\n","    self.fc = nn.Linear(hidden_size, output_size)  \n","    self.attn = nn.Linear(hidden_size+embedding_size, self.max_length)\n","    if(bidirectional):\n","      self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size)\n","    else :\n","      self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n","\n","  def forward(self, x,output, hidden, cell = 0):\n","    x = x.unsqueeze(0)\n","    output=output.permute(1,0,2)\n","    embedded = self.embedding(x)\n","    embedded = self.dropout(embedded)\n","    attn_weights = F.softmax(self.attn(torch.cat((embedded[0],hidden[0]), 1)), dim = 1)\n","    attn_applied = torch.bmm(attn_weights.unsqueeze(1),output)\n","    attn_applied = attn_applied.squeeze(1)\n","    op = torch.cat((embedded[0], attn_applied), 1)\n","\n","    op = self.attn_combine(op).unsqueeze(0)\n","    op = F.relu(op)\n","    if(self.cell_type == \"GRU\"):\n","        outputs, hidden = self.gru(op, hidden)\n","    if(self.cell_type == \"RNN\"):\n","        outputs, hidden = self.rnn(op, hidden)\n","    if(self.cell_type == \"LSTM\"):\n","        outputs, (hidden, cell) = self.lstm(op, (hidden, cell))\n","    predictions = self.fc(outputs)\n","    # shape of predictions: (1, N, length_of_vocab)\n","    predictions = predictions.squeeze(0)\n","    # shape of predictions: (N, length_of_vocab)\n","    if(self.cell_type == \"LSTM\"):\n","        return predictions, hidden, cell\n","    return predictions, hidden\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkWSEAca-Okj","trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, cell_type, bidirectional, enc_layers, dec_layers):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.cell_type = cell_type\n","        self.bidirectional = bidirectional\n","        self.enc_layers = enc_layers\n","        self.dec_layers = dec_layers\n","\n","    def forward(self, source, target, teacher_force_ratio=0.5):\n","        batch_size = source.shape[1]\n","        target_len = target.shape[0]\n","        target_vocab_size = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","        if(self.cell_type == \"LSTM\"):\n","            encoder_output, hidden, cell = self.encoder(source)\n","        else:\n","            encoder_output, hidden = self.encoder(source)\n","        # if(self.bidirectional == True):\n","        if(self.enc_layers != self.dec_layers or self.bidirectional == True):\n","          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n","          hidden = hidden.repeat(self.dec_layers,1,1)\n","          if(self.cell_type == \"LSTM\"):\n","              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n","              cell = cell.repeat(self.dec_layers,1,1)\n","        \n","        x = target[0]\n","    \n","        for t in range(1, target_len):\n","#             print(\"STARTED t= \",t)\n","            if(self.cell_type == \"LSTM\"):\n","                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n","            else :\n","                output, hidden = self.decoder(x, encoder_output, hidden)\n","            outputs[t] = output\n","\n","            best_guess = output.argmax(1)\n","\n","            x = target[t] if random.random() < teacher_force_ratio else best_guess\n","            \n","#         print(\"decoder sucessful\")\n","        return outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYajaq47-xUQ","trusted":true},"outputs":[],"source":["def Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size):\n","    correct_count = 0\n","    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n","        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","        output = model.forward(inp_data.T, target.T, 0)\n","        output = nn.Softmax(dim=2)(output)\n","        output = torch.argmax(output, dim=2)\n","        \n","        output = output.T\n","        for i in range(batch_size):\n","            if(torch.equal(output[i][1:],target[i][1:])):\n","                correct_count += 1\n","    accuracy = correct_count * 100 / len(english_matrix)\n","    return accuracy\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QCnSmaTMRSR","trusted":true},"outputs":[],"source":["def neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention):\n","  learning_rate = 1e-3\n","  num_epochs = 20\n","  input_size_encoder = len(english_char_list) + 2  # intially= 30 || Now 26 + 1(start token) + 1 = 28 \n","  input_size_decoder = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","  output_size        = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","\n","  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, enc_layers, enc_dropout, cell_type,bidirectional).to(device)\n","  if(attention):\n","    decoder_net = Atten_decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type, bidirectional).to(device)\n","  else:\n","    decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type).to(device)\n","\n","  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, enc_layers, dec_layers).to(device)\n","  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","  pad_idx = len(marathi_char_list) + 1  # 64 # pading index for marathi\n","  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","\n","\n","  for epoch in range(num_epochs):\n","      print(\"epoch = \",epoch)\n","\n","      model.train()\n","      total_loss = 0\n","      step = 0\n","      for batch_idx in range((int)(len(english_matrix) / batch_size)):\n","\n","          # Forward prop\n","          inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","          target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","  #         inp_data = inp_data.T\n","          target = target.T\n","          output = model(inp_data.T, target)\n","\n","          output = output[1:].reshape(-1, output.shape[2])\n","          target = target[1:].reshape(-1)\n","          optimizer.zero_grad()\n","          loss = criterion(output, target)\n","          total_loss += loss\n","          # Back prop\n","          loss.backward()\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","          # Gradient descent step\n","          optimizer.step()\n","\n","          step += 1\n","      print(\"total loss = \",total_loss / step)\n","      training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size)\n","      print(\"Training Accuracy = \", training_accuracy)\n","      val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch, batch_size)\n","      print(\"Validation accuracy = \",val_accuracy)\n","      test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch, batch_size)\n","      print(\"Test accuracy = \", test_accuracy)\n","      wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': epoch})\n","      if(epoch > 10 and training_accuracy < 10):\n","        return\n","      if(epoch > 5 and training_accuracy < 1):\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkkdB4_mxLWV","outputId":"d8d86c27-e9b7-42bd-b87e-47e73ab72031"},"outputs":[],"source":["# cell_type = \"RNN\"\n","# bidirectional = True\n","# enc_layers = 3\n","# dec_layers = 2\n","# batch_size = 256\n","# embedding_size = 384\n","# hidden_size = 256\n","# dropout = 0.3\n","# enc_dropout = 0.3\n","# dec_dropout = 0.6\n","# attention = True\n","\n","\n","# neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hul3BAih-xUR","trusted":true},"outputs":[],"source":["def run_NN():\n","    \n","\n","    # Initialize a new wandb run\n","    wandb.init()\n","    \n","    # Config is a variable that holds and saves hyperparameters and inputs\n","    config = wandb.config\n","\n","    # Local variables, values obtained from wandb config\n","    \n","    cell_type = config.cell_type\n","    attention = config.attention\n","    bidirectional = config.bidirectional\n","    enc_layers = config.enc_layers\n","    dec_layers = config.dec_layers\n","    batch_size = config.batch_size\n","    embedding_size = config.embedding_size\n","    hidden_size = config.hidden_size\n","    enc_dropout = config.enc_dropout\n","    dec_dropout = config.dec_dropout\n","\n","    # Display the hyperparameters\n","    run_name = \"ct_{}_at_{}_bd_{}_enl_{}_dnl_{}_bs_{}_es_{}_hs_{}_edo_{}_ddo_{}\".format(cell_type, attention, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout)\n","    print(run_name)\n","    neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)\n","    wandb.run.name = run_name\n","    wandb.run.save()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-qwOMgXc-xUR"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyvrYxCd-xUS","trusted":true},"outputs":[],"source":["sweep_config = {\n","  \"name\": \"CS6910 Assignment 3\",\n","  \"metric\": {\n","      \"name\":\"validation_accuracy\",\n","      \"goal\": \"maximize\"\n","  },\n","  \"method\": \"bayes\",\n","  \"parameters\": {\n","        \n","       \n","        \"cell_type\": {\n","            \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n","        },\n","        \"attention\": {\n","            \"values\": [True, False]\n","        },\n","        \"bidirectional\": {\n","            \"values\": [True, False]\n","        },\n","        \"enc_layers\": {\n","            \"values\": [1, 2, 3, 5]\n","        },\n","        \"dec_layers\": {\n","            \"values\": [1, 2, 3, 5]\n","        },\n","        \"batch_size\": {\n","            \"values\": [64, 128, 256]\n","        },\n","        \"embedding_size\": {\n","            \"values\": [16, 32, 64,128, 256, 384, 512]\n","        },\n","        \"hidden_size\": {\n","            \"values\": [16,32,64,128, 256, 384, 512]\n","        },\n","        \"enc_dropout\": {\n","            \"values\": [0,0.2,0.3,0.4,0.6]\n","        },\n","        \"dec_dropout\": {\n","            \"values\": [0,0.2,0.3,0.4,0.6]\n","        }\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"rajmahajan24\", project=\"DL_Assignment_3\")\n","wandb.agent(sweep_id, run_NN, count=1200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67svBk48GAaX","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bW22hUA2vTpV","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMyJeinM-xUS","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9sr6TtgPdmn","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crRv0WD-Hu6V"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LyTr7QZKMqQG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1reXcQN1-xUT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrNT-rKM-xUT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPoWLZG3-xUT"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
=======
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-04T09:43:50.322100Z"},"id":"FsMRpLJt_egZ","trusted":true},"outputs":[],"source":["# DL Assignment 3\n","# version 19.\n","# project name changed to final project name.\n","# added if condition for early stopping of less accuracy runs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDghhjha-xUK","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADfNyi1sB9L3","trusted":true},"outputs":[],"source":["import numpy as np\n","import math\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from keras.datasets import fashion_mnist\n","from sklearn.model_selection import train_test_split\n","\n","\n","# from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeBoqlNt-xUM","outputId":"abc676c5-4f51-4990-ec65-62947ad08b9b","trusted":true},"outputs":[],"source":["# device = \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtCn6lShP54p","trusted":true},"outputs":[],"source":["!pip install wandb\n","import wandb\n","wandb.login(key = \"c28eda24dacbd50a57332e445cfdfb2f4c16799c\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf7JgsItwUtY","trusted":true},"outputs":[],"source":["\n","# import wandb\n","wandb.init(project=\"DL_Assignment_3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6Agml7HAllJ","outputId":"969bc4ab-d668-488d-a48f-02587151f499","trusted":true},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"299AqvvaEdkf","trusted":true},"outputs":[],"source":["\n","path = '/kaggle/input/marathi/mar_train.csv'\n","path_val = '/kaggle/input/marathi/mar_valid.csv'\n","path_test = '/kaggle/input/marathi/mar_test.csv'\n","# path = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv'\n","# path_val = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv'\n","# path_test = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtpQ9UGxFhkU","outputId":"0e3e484e-b5c2-4081-e2a9-8555b59ba76d","trusted":true},"outputs":[],"source":["df = pd.read_csv(path , header = None)\n","# df.head()\n","df_val = pd.read_csv(path_val , header = None)\n","df_test = pd.read_csv(path_test , header = None)\n","english_words_val = df_val[0]\n","marathi_words_val = df_val[1]\n","english_words_test = df_test[0]\n","marathi_words_test = df_test[1]\n","english_words = df[0]\n","marathi_words = df[1]\n","# print(english_words)\n","# print(marathi_words)\n","print(df[50000:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtlfObKubBNq","outputId":"9d3d45e2-c809-49f0-a98b-407791473f74","trusted":true},"outputs":[],"source":["# creating list of charecters in both languages\n","\n","english_char_list = []\n","max_length_word_english = -1\n","for word in english_words:\n","  max_length_word_english = max(max_length_word_english,len(word)) \n","  for char in word :\n","    english_char_list.append(char);\n","english_char_list = list(set(english_char_list))\n","english_char_list.sort()\n","# print(len(english_char_list))\n","print(english_char_list)\n","# print(max_length_word_english)\n","\n","marathi_char_list = []\n","max_length_word_marathi = -1\n","for word in marathi_words:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","  for char in word :\n","    marathi_char_list.append(char);\n","marathi_char_list = list(set(marathi_char_list))\n","marathi_char_list.sort()\n","# print(len(marathi_char_list))\n","print(marathi_char_list)\n","\n","\n","# finding out the maximum size word for english and marathi from validation and test data.\n","for word in english_words_val:\n","  max_length_word_english = max(max_length_word_english,len(word))\n","for word in english_words_test:\n","  max_length_word_english = max(max_length_word_english,len(word)) \n","for word in marathi_words_val:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","for word in marathi_words_test:\n","  max_length_word_marathi = max(max_length_word_marathi,len(word))\n","\n","print(max_length_word_english)\n","print(max_length_word_marathi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdcqBaU70W3v","trusted":true},"outputs":[],"source":["# english word to vector size = 27 ie. max_length_word_english\n","# marathi word to vector size = 20 ie. max_length_word_marathi\n","# for one word.\n","def word2vec(word, lang):\n","  vec = []\n","  if(lang == \"english\"):\n","    vec.append(len(english_char_list) + 1)\n","    for char in word:\n","      for i in range(len(english_char_list)):\n","        if(english_char_list[i] == char):\n","          vec.append(i+1)\n","    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n","#         vec.append(len(english_char_list) + 2)\n","        vec.append(0)\n","#     vec.append(len(english_char_list) + 2)\n","    vec.append(0)\n","  else :\n","    vec.append(len(marathi_char_list) + 1)\n","    for char in word:\n","      for i in range(len(marathi_char_list)):\n","        if( marathi_char_list[i] == char):\n","          vec.append(i+1)\n","    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n","#         vec.append(len(marathi_char_list) + 2)\n","        vec.append(0)\n","#     vec.append(len(marathi_char_list) + 2)\n","    vec.append(0)\n","  return(vec)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heu_03Y3332P","outputId":"399f1147-655c-4ff2-f9d9-224a5976b452","trusted":true},"outputs":[],"source":["vec = word2vec(marathi_words[10],\"marathi\")\n","print(marathi_words[10])\n","print(vec)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRObgwk5pcEz","trusted":true},"outputs":[],"source":["# creating matrix of representation for whole words of english and marathi.\n","\n","def ip_matrix_construct(words, lang):\n","  ans = []\n","  for word in words:\n","    ans.append(word2vec(word, lang))\n","  return(ans)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FgS76C6rluA","outputId":"beb676a0-b54d-478b-e437-7cb0c13341b5","trusted":true},"outputs":[],"source":["# calculated representations of whole english and marathi words in variables english and marathi matrix.\n","english_matrix = ip_matrix_construct(english_words, \"english\")\n","marathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n","# english_matrix = english_matrix[:1000]\n","# marathi_matrix = marathi_matrix[:1000]\n","print(len(english_matrix))\n","print(len(marathi_matrix))\n","english_matrix = torch.tensor(english_matrix)\n","marathi_matrix = torch.tensor(marathi_matrix)\n","print(len(english_matrix[0]))\n","print(len(marathi_matrix[0]))\n","\n","english_matrix_val = ip_matrix_construct(english_words_val, \"english\")\n","marathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\n","english_matrix_val = torch.tensor(english_matrix_val)\n","marathi_matrix_val = torch.tensor(marathi_matrix_val)\n","english_matrix_test = ip_matrix_construct(english_words_test, \"english\")\n","marathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\n","english_matrix_test = torch.tensor(english_matrix_test)\n","marathi_matrix_test = torch.tensor(marathi_matrix_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvjQGsLrsBJZ","trusted":true},"outputs":[],"source":["# alaadin\n","# input size = number of characters in lang eg, english = 26 + 1 for start of sentence + 1 for end of sentence.\n","# embedding size  = hyperparamter\n","# hidden size = hyperparametrv \n","# num layers  = hyperparametr\n","class Encoder(nn.Module):\n","  def __init__(self,input_size, embedding_size, hidden_size, enc_layers, p, cell_type, bidirectional):\n","    super(Encoder,self).__init__()\n","    self.hidden_size = hidden_size\n","    self.enc_layers = enc_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.bidirectional = bidirectional\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n","\n","  def forward(self, x):\n","    # x shape: (seq_length, N)  where N is batch size\n","#     print(\"shape of x\")\n","#     print(x.shape)\n","    embedding = self.dropout(self.embedding(x))\n","#     print(\"shape of embedding\")\n","#     print(embedding.shape)\n","    # embedding shape : (seq_length, N, embedding_size)\n","    if(self.cell_type == \"GRU\"):\n","      output, hidden = self.gru(embedding)\n","    if(self.cell_type == \"RNN\"):\n","      output, hidden = self.rnn(embedding)\n","    if(self.cell_type == \"LSTM\"):\n","      outputs, (hidden,cell) = self.lstm(embedding)\n","      # print(\"hidden.shape\",hidden.shape)\n","      # print(\"cell.shape\",cell.shape)\n","      return outputs, hidden, cell\n","    # print(\"output.shape\",output.shape)\n","    # print(\"hidden.shape\",hidden.shape)\n","#     print(output.size())\n","    return output, hidden\n","\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nea9Nz5E-xUP","trusted":true},"outputs":[],"source":["# alaadin\n","# input size = number of characters for target lang eg, marathi = 63\n","# embedidng size = will be sae as above.\n","# hidden size = same as above\n","# output size = same as input size ie. number of characters for target lang eg, marathi = 63\n","# num layers = same as above\n","class Decoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type):\n","    super(Decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.dec_layers = dec_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout = p)\n","    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n","  \n","  def forward(self,x,output, hidden, cell = 0):\n","    # shape of x: (N) but we want (1,N)\n","    x = x.unsqueeze(0).int()\n","#     print(\"shape of x\")\n","#     print(x.shape)\n","    embedding = self.dropout(self.embedding(x))\n","    # embedding shape : (1,N,embedding_size)\n","#     print(\"embedding shape\")\n","#     print(embedding.shape)\n","    if(self.cell_type == \"GRU\"):\n","        outputs, hidden = self.gru(embedding, hidden)\n","    if(self.cell_type == \"RNN\"):\n","        outputs, hidden = self.rnn(embedding, hidden)\n","    if(self.cell_type == \"LSTM\"):\n","        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n","    # shape of outputs: (1, N, hidden_size)\n","    predictions = self.fc(outputs)\n","    # shape of predictions: (1, N, length_of_vocab)\n","    predictions = predictions.squeeze(0)\n","    # shape of predictions: (N, length_of_vocab)\n","    if(self.cell_type == \"LSTM\"):\n","        return predictions, hidden, cell\n","    return predictions, hidden\n","\n","\n","  def initHidden(self):\n","#     print(\"init hidden decoder\")\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmqgOzhw0t37"},"outputs":[],"source":["class Atten_decoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, bidirectional):\n","    super(Atten_decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    # self.dropout_p = dropout_p\n","    self.max_length = len(english_matrix[0])  #30\n","    self.dec_layers = dec_layers\n","    self.dropout = nn.Dropout(p)\n","    self.cell_type = cell_type\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    if(cell_type == \"GRU\"):\n","      self.gru = nn.GRU(hidden_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"RNN\"):\n","      self.rnn = nn.RNN(hidden_size, hidden_size, dec_layers, dropout = p)\n","    if(cell_type == \"LSTM\"):\n","      self.lstm = nn.LSTM(hidden_size, hidden_size, dec_layers, dropout = p)\n","    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n","    self.attn = nn.Linear(hidden_size+embedding_size, self.max_length)\n","    if(bidirectional):\n","      self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size)\n","    else :\n","      self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n","\n","  def forward(self, x,output, hidden, cell = 0):\n","    x = x.unsqueeze(0)\n","    output=output.permute(1,0,2)\n","    embedded = self.embedding(x)\n","    embedded = self.dropout(embedded)\n","    attn_weights = F.softmax(self.attn(torch.cat((embedded[0],hidden[0]), 1)), dim = 1)\n","    attn_applied = torch.bmm(attn_weights.unsqueeze(1),output)\n","    attn_applied = attn_applied.squeeze(1)\n","    op = torch.cat((embedded[0], attn_applied), 1)\n","\n","    op = self.attn_combine(op).unsqueeze(0)\n","    op = F.relu(op)\n","    if(self.cell_type == \"GRU\"):\n","        outputs, hidden = self.gru(op, hidden)\n","    if(self.cell_type == \"RNN\"):\n","        outputs, hidden = self.rnn(op, hidden)\n","    if(self.cell_type == \"LSTM\"):\n","        outputs, (hidden, cell) = self.lstm(op, (hidden, cell))\n","    predictions = self.fc(outputs)\n","    # shape of predictions: (1, N, length_of_vocab)\n","    predictions = predictions.squeeze(0)\n","    # shape of predictions: (N, length_of_vocab)\n","    if(self.cell_type == \"LSTM\"):\n","        return predictions, hidden, cell\n","    return predictions, hidden\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkWSEAca-Okj","trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, cell_type, bidirectional, enc_layers, dec_layers):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.cell_type = cell_type\n","        self.bidirectional = bidirectional\n","        self.enc_layers = enc_layers\n","        self.dec_layers = dec_layers\n","#         print(\"seq2seq intilized\")\n","\n","    def forward(self, source, target, teacher_force_ratio=0.5):\n","        batch_size = source.shape[1]\n","        target_len = target.shape[0]\n","        target_vocab_size = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","        if(self.cell_type == \"LSTM\"):\n","            encoder_output, hidden, cell = self.encoder(source)\n","        else:\n","            encoder_output, hidden = self.encoder(source)\n","        # if(self.bidirectional == True):\n","        if(self.enc_layers != self.dec_layers or self.bidirectional == True):\n","          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n","          hidden = hidden.repeat(self.dec_layers,1,1)\n","          if(self.cell_type == \"LSTM\"):\n","              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n","              cell = cell.repeat(self.dec_layers,1,1)\n","        \n","        # Grab the first input to the Decoder which will be <SOS> token\n","        x = target[0]\n","    \n","        for t in range(1, target_len):\n","#             print(\"STARTED t= \",t)\n","            if(self.cell_type == \"LSTM\"):\n","                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n","            else :\n","                output, hidden = self.decoder(x, encoder_output, hidden)\n","#             print(\"output shape = \",output.shape)\n","#             print(\"hidden.shape = \", hidden.shape)\n","            # Store next output prediction\n","            outputs[t] = output\n","\n","            # Get the best word the Decoder predicted (index in the vocabulary)\n","            best_guess = output.argmax(1)\n","\n","            x = target[t] if random.random() < teacher_force_ratio else best_guess\n","#             print(\"x.shape = \",x.shape)\n","#             print(\"COMPLETED t \", t)\n","            \n","#         print(\"decoder sucessful\")\n","        return outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYajaq47-xUQ","trusted":true},"outputs":[],"source":["def Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size):\n","    correct_count = 0\n","    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n","        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","        output = model.forward(inp_data.T, target.T, 0)\n","        output = nn.Softmax(dim=2)(output)\n","        output = torch.argmax(output, dim=2)\n","        \n","        output = output.T\n","#         print(output[1])\n","#         print(output[1][1:])\n","#         print(\"output.shape = \",output.shape)\n","#         print(\"target.shape = \",target.shape)\n","        for i in range(batch_size):\n","            if(torch.equal(output[i][1:],target[i][1:])):\n","                correct_count += 1\n","    accuracy = correct_count * 100 / len(english_matrix)\n","    return accuracy\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QCnSmaTMRSR","trusted":true},"outputs":[],"source":["def neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention):\n","  learning_rate = 1e-3\n","  num_epochs = 20\n","  input_size_encoder = len(english_char_list) + 2  # intially= 30 || Now 26 + 1(start token) + 1 = 28 \n","  input_size_decoder = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","  output_size        = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n","\n","  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, enc_layers, enc_dropout, cell_type,bidirectional).to(device)\n","  if(attention):\n","    decoder_net = Atten_decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type, bidirectional).to(device)\n","  else:\n","    decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type).to(device)\n","\n","  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, enc_layers, dec_layers).to(device)\n","  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","  pad_idx = len(marathi_char_list) + 1  # 64 # pading index for marathi\n","  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","\n","\n","  for epoch in range(num_epochs):\n","      print(\"epoch = \",epoch)\n","\n","      model.train()\n","      total_loss = 0\n","      step = 0\n","      for batch_idx in range((int)(len(english_matrix) / batch_size)):\n","          # Get input and targets and get to cuda\n","  #         inp_data = batch.src.to(device)\n","  #         target = batch.trg.to(device)\n","\n","          # Forward prop\n","          inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","          target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n","  #         inp_data = inp_data.T\n","          target = target.T\n","          output = model(inp_data.T, target)\n","  #         print(\"model successful\")\n","  #         print(\"output.shape = \",output.shape)\n","\n","          output = output[1:].reshape(-1, output.shape[2])\n","          target = target[1:].reshape(-1)\n","  #         print(\"output.shape = \",output.shape)\n","  #         print(\"target.shape = \",target.shape)\n","          optimizer.zero_grad()\n","          loss = criterion(output, target)\n","          total_loss += loss\n","          # Back prop\n","          loss.backward()\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","          # Gradient descent step\n","          optimizer.step()\n","\n","          step += 1\n","  #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n","      print(\"total loss = \",total_loss / step)\n","      training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size)\n","      print(\"Training Accuracy = \", training_accuracy)\n","      val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch, batch_size)\n","      print(\"Validation accuracy = \",val_accuracy)\n","      test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch, batch_size)\n","      print(\"Test accuracy = \", test_accuracy)\n","      wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': epoch})\n","      if(epoch > 10 and training_accuracy < 10):\n","        return\n","      if(epoch > 5 and training_accuracy < 1):\n","        return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkkdB4_mxLWV","outputId":"d8d86c27-e9b7-42bd-b87e-47e73ab72031"},"outputs":[],"source":["# cell_type = \"RNN\"\n","# bidirectional = True\n","# enc_layers = 3\n","# dec_layers = 2\n","# batch_size = 256\n","# embedding_size = 384\n","# hidden_size = 256\n","# dropout = 0.3\n","# enc_dropout = 0.3\n","# dec_dropout = 0.6\n","# attention = True\n","\n","\n","# neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hul3BAih-xUR","trusted":true},"outputs":[],"source":["def run_NN():\n","    \n","\n","    # Initialize a new wandb run\n","    wandb.init()\n","    \n","    # Config is a variable that holds and saves hyperparameters and inputs\n","    config = wandb.config\n","\n","    # Local variables, values obtained from wandb config\n","    \n","    cell_type = config.cell_type\n","    attention = config.attention\n","    bidirectional = config.bidirectional\n","    enc_layers = config.enc_layers\n","    dec_layers = config.dec_layers\n","    batch_size = config.batch_size\n","    embedding_size = config.embedding_size\n","    hidden_size = config.hidden_size\n","    enc_dropout = config.enc_dropout\n","    dec_dropout = config.dec_dropout\n","\n","    # Display the hyperparameters\n","    run_name = \"ct_{}_at_{}_bd_{}_enl_{}_dnl_{}_bs_{}_es_{}_hs_{}_edo_{}_ddo_{}\".format(cell_type, attention, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout)\n","    print(run_name)\n","    neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)\n","    wandb.run.name = run_name\n","    wandb.run.save()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-qwOMgXc-xUR"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyvrYxCd-xUS","trusted":true},"outputs":[],"source":["sweep_config = {\n","  \"name\": \"CS6910 Assignment 3\",\n","  \"metric\": {\n","      \"name\":\"validation_accuracy\",\n","      \"goal\": \"maximize\"\n","  },\n","  \"method\": \"bayes\",\n","  \"parameters\": {\n","        \n","       \n","        \"cell_type\": {\n","            \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n","        },\n","        \"attention\": {\n","            \"values\": [True, False]\n","        },\n","        \"bidirectional\": {\n","            \"values\": [True, False]\n","        },\n","        \"enc_layers\": {\n","            \"values\": [1, 2, 3, 5]\n","        },\n","        \"dec_layers\": {\n","            \"values\": [1, 2, 3, 5]\n","        },\n","        \"batch_size\": {\n","            \"values\": [64, 128, 256]\n","        },\n","        \"embedding_size\": {\n","            \"values\": [16, 32, 64,128, 256, 384, 512]\n","        },\n","        \"hidden_size\": {\n","            \"values\": [16,32,64,128, 256, 384, 512]\n","        },\n","        \"enc_dropout\": {\n","            \"values\": [0,0.2,0.3,0.4,0.6]\n","        },\n","        \"dec_dropout\": {\n","            \"values\": [0,0.2,0.3,0.4,0.6]\n","        }\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, entity=\"rajmahajan24\", project=\"DL_Assignment_3\")\n","wandb.agent(sweep_id, run_NN, count=1200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67svBk48GAaX","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bW22hUA2vTpV","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMyJeinM-xUS","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9sr6TtgPdmn","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crRv0WD-Hu6V"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LyTr7QZKMqQG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1reXcQN1-xUT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrNT-rKM-xUT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPoWLZG3-xUT"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
>>>>>>> 2a22251cbf08a820aa293ed76e6e89aae795674e
