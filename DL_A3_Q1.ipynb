{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# DL Assignment 3\n\n# version 19.\n# project name changed to final project name.\n# added if condition for early stopping of less accuracy runs.","metadata":{"id":"FsMRpLJt_egZ","execution":{"iopub.status.busy":"2023-05-04T09:43:50.322100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"DDghhjha-xUK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.datasets import fashion_mnist\nfrom sklearn.model_selection import train_test_split\n\n\n# from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"ADfNyi1sB9L3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = \"cpu\"\nprint(device)","metadata":{"id":"EeBoqlNt-xUM","outputId":"abc676c5-4f51-4990-ec65-62947ad08b9b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login(key = \"c28eda24dacbd50a57332e445cfdfb2f4c16799c\")\n","metadata":{"id":"KtCn6lShP54p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import wandb\nwandb.init(project=\"DL_Assignment_3\")","metadata":{"id":"Qf7JgsItwUtY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive/')\n","metadata":{"id":"H6Agml7HAllJ","outputId":"969bc4ab-d668-488d-a48f-02587151f499","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npath = '/kaggle/input/marathi/mar_train.csv'\npath_val = '/kaggle/input/marathi/mar_valid.csv'\npath_test = '/kaggle/input/marathi/mar_test.csv'\n# path = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv'\n# path_val = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv'\n# path_test = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv'","metadata":{"id":"299AqvvaEdkf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path , header = None)\n# df.head()\ndf_val = pd.read_csv(path_val , header = None)\ndf_test = pd.read_csv(path_test , header = None)\nenglish_words_val = df_val[0]\nmarathi_words_val = df_val[1]\nenglish_words_test = df_test[0]\nmarathi_words_test = df_test[1]\nenglish_words = df[0]\nmarathi_words = df[1]\n# print(english_words)\n# print(marathi_words)\nprint(df[50000:])","metadata":{"id":"NtpQ9UGxFhkU","outputId":"0e3e484e-b5c2-4081-e2a9-8555b59ba76d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating list of charecters in both languages\n\nenglish_char_list = []\nmax_length_word_english = -1\nfor word in english_words:\n  max_length_word_english = max(max_length_word_english,len(word)) \n  for char in word :\n    english_char_list.append(char);\nenglish_char_list = list(set(english_char_list))\nenglish_char_list.sort()\n# print(len(english_char_list))\nprint(english_char_list)\n# print(max_length_word_english)\n\nmarathi_char_list = []\nmax_length_word_marathi = -1\nfor word in marathi_words:\n  max_length_word_marathi = max(max_length_word_marathi,len(word))\n  for char in word :\n    marathi_char_list.append(char);\nmarathi_char_list = list(set(marathi_char_list))\nmarathi_char_list.sort()\n# print(len(marathi_char_list))\nprint(marathi_char_list)\n\n\n# finding out the maximum size word for english and marathi from validation and test data.\nfor word in english_words_val:\n  max_length_word_english = max(max_length_word_english,len(word))\nfor word in english_words_test:\n  max_length_word_english = max(max_length_word_english,len(word)) \nfor word in marathi_words_val:\n  max_length_word_marathi = max(max_length_word_marathi,len(word))\nfor word in marathi_words_test:\n  max_length_word_marathi = max(max_length_word_marathi,len(word))\n\nprint(max_length_word_english)\nprint(max_length_word_marathi)","metadata":{"id":"mtlfObKubBNq","outputId":"9d3d45e2-c809-49f0-a98b-407791473f74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# english word to vector size = 27 ie. max_length_word_english\n# marathi word to vector size = 20 ie. max_length_word_marathi\n# for one word.\ndef word2vec(word, lang):\n  vec = []\n  if(lang == \"english\"):\n    vec.append(len(english_char_list) + 1)\n    for char in word:\n      for i in range(len(english_char_list)):\n        if(english_char_list[i] == char):\n          vec.append(i+1)\n    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n#         vec.append(len(english_char_list) + 2)\n        vec.append(0)\n#     vec.append(len(english_char_list) + 2)\n    vec.append(0)\n  else :\n    vec.append(len(marathi_char_list) + 1)\n    for char in word:\n      for i in range(len(marathi_char_list)):\n        if( marathi_char_list[i] == char):\n          vec.append(i+1)\n    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n#         vec.append(len(marathi_char_list) + 2)\n        vec.append(0)\n#     vec.append(len(marathi_char_list) + 2)\n    vec.append(0)\n  return(vec)\n","metadata":{"id":"fdcqBaU70W3v","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vec = word2vec(marathi_words[10],\"marathi\")\nprint(marathi_words[10])\nprint(vec)","metadata":{"id":"heu_03Y3332P","outputId":"399f1147-655c-4ff2-f9d9-224a5976b452","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating matrix of representation for whole words of english and marathi.\n\ndef ip_matrix_construct(words, lang):\n  ans = []\n  for word in words:\n    ans.append(word2vec(word, lang))\n  return(ans)","metadata":{"id":"pRObgwk5pcEz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculated representations of whole english and marathi words in variables english and marathi matrix.\nenglish_matrix = ip_matrix_construct(english_words, \"english\")\nmarathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n# english_matrix = english_matrix[:1000]\n# marathi_matrix = marathi_matrix[:1000]\nprint(len(english_matrix))\nprint(len(marathi_matrix))\nenglish_matrix = torch.tensor(english_matrix)\nmarathi_matrix = torch.tensor(marathi_matrix)\nprint(len(english_matrix[0]))\nprint(len(marathi_matrix[0]))\n\nenglish_matrix_val = ip_matrix_construct(english_words_val, \"english\")\nmarathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\nenglish_matrix_val = torch.tensor(english_matrix_val)\nmarathi_matrix_val = torch.tensor(marathi_matrix_val)\nenglish_matrix_test = ip_matrix_construct(english_words_test, \"english\")\nmarathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\nenglish_matrix_test = torch.tensor(english_matrix_test)\nmarathi_matrix_test = torch.tensor(marathi_matrix_test)","metadata":{"id":"1FgS76C6rluA","outputId":"beb676a0-b54d-478b-e437-7cb0c13341b5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alaadin\n# input size = number of characters in lang eg, english = 26 + 1 for start of sentence + 1 for end of sentence.\n# embedding size  = hyperparamter\n# hidden size = hyperparametrv \n# num layers  = hyperparametr\nclass Encoder(nn.Module):\n  def __init__(self,input_size, embedding_size, hidden_size, enc_layers, p, cell_type, bidirectional):\n    super(Encoder,self).__init__()\n    self.hidden_size = hidden_size\n    self.enc_layers = enc_layers\n    self.dropout = nn.Dropout(p)\n    self.cell_type = cell_type\n    self.bidirectional = bidirectional\n    self.embedding = nn.Embedding(input_size, embedding_size)\n    if(cell_type == \"GRU\"):\n      self.gru = nn.GRU(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n    if(cell_type == \"RNN\"):\n      self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n    if(cell_type == \"LSTM\"):\n      self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n\n  def forward(self, x):\n    # x shape: (seq_length, N)  where N is batch size\n#     print(\"shape of x\")\n#     print(x.shape)\n    embedding = self.dropout(self.embedding(x))\n#     print(\"shape of embedding\")\n#     print(embedding.shape)\n    # embedding shape : (seq_length, N, embedding_size)\n    if(self.cell_type == \"GRU\"):\n      output, hidden = self.gru(embedding)\n    if(self.cell_type == \"RNN\"):\n      output, hidden = self.rnn(embedding)\n    if(self.cell_type == \"LSTM\"):\n      outputs, (hidden,cell) = self.lstm(embedding)\n      # print(\"hidden.shape\",hidden.shape)\n      # print(\"cell.shape\",cell.shape)\n      return outputs, hidden, cell\n    # print(\"output.shape\",output.shape)\n    # print(\"hidden.shape\",hidden.shape)\n#     print(output.size())\n    return output, hidden\n\n  def initHidden(self):\n    return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"id":"cvjQGsLrsBJZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alaadin\n# input size = number of characters for target lang eg, marathi = 63\n# embedidng size = will be sae as above.\n# hidden size = same as above\n# output size = same as input size ie. number of characters for target lang eg, marathi = 63\n# num layers = same as above\nclass Decoder(nn.Module):\n  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type):\n    super(Decoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.dec_layers = dec_layers\n    self.dropout = nn.Dropout(p)\n    self.cell_type = cell_type\n    self.embedding = nn.Embedding(input_size, embedding_size)\n    if(cell_type == \"GRU\"):\n      self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout = p)\n    if(cell_type == \"RNN\"):\n      self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout = p)\n    if(cell_type == \"LSTM\"):\n      self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout = p)\n    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n  \n  def forward(self,x,output, hidden, cell = 0):\n    # shape of x: (N) but we want (1,N)\n    x = x.unsqueeze(0).int()\n#     print(\"shape of x\")\n#     print(x.shape)\n    embedding = self.dropout(self.embedding(x))\n    # embedding shape : (1,N,embedding_size)\n#     print(\"embedding shape\")\n#     print(embedding.shape)\n    if(self.cell_type == \"GRU\"):\n        outputs, hidden = self.gru(embedding, hidden)\n    if(self.cell_type == \"RNN\"):\n        outputs, hidden = self.rnn(embedding, hidden)\n    if(self.cell_type == \"LSTM\"):\n        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n    # shape of outputs: (1, N, hidden_size)\n    predictions = self.fc(outputs)\n    # shape of predictions: (1, N, length_of_vocab)\n    predictions = predictions.squeeze(0)\n    # shape of predictions: (N, length_of_vocab)\n    if(self.cell_type == \"LSTM\"):\n        return predictions, hidden, cell\n    return predictions, hidden\n\n\n  def initHidden(self):\n#     print(\"init hidden decoder\")\n    return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"id":"nea9Nz5E-xUP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Atten_decoder(nn.Module):\n  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, bidirectional):\n    super(Atten_decoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    # self.dropout_p = dropout_p\n    self.max_length = len(english_matrix[0])  #30\n    self.dec_layers = dec_layers\n    self.dropout = nn.Dropout(p)\n    self.cell_type = cell_type\n    self.embedding = nn.Embedding(input_size, embedding_size)\n    if(cell_type == \"GRU\"):\n      self.gru = nn.GRU(hidden_size, hidden_size, dec_layers, dropout = p)\n    if(cell_type == \"RNN\"):\n      self.rnn = nn.RNN(hidden_size, hidden_size, dec_layers, dropout = p)\n    if(cell_type == \"LSTM\"):\n      self.lstm = nn.LSTM(hidden_size, hidden_size, dec_layers, dropout = p)\n    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n    self.attn = nn.Linear(hidden_size+embedding_size, self.max_length)\n    if(bidirectional):\n      self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size)\n    else :\n      self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n\n  def forward(self, x,output, hidden, cell = 0):\n    x = x.unsqueeze(0)\n    output=output.permute(1,0,2)\n    embedded = self.embedding(x)\n    embedded = self.dropout(embedded)\n    attn_weights = F.softmax(self.attn(torch.cat((embedded[0],hidden[0]), 1)), dim = 1)\n    attn_applied = torch.bmm(attn_weights.unsqueeze(1),output)\n    attn_applied = attn_applied.squeeze(1)\n    op = torch.cat((embedded[0], attn_applied), 1)\n\n    op = self.attn_combine(op).unsqueeze(0)\n    op = F.relu(op)\n    if(self.cell_type == \"GRU\"):\n        outputs, hidden = self.gru(op, hidden)\n    if(self.cell_type == \"RNN\"):\n        outputs, hidden = self.rnn(op, hidden)\n    if(self.cell_type == \"LSTM\"):\n        outputs, (hidden, cell) = self.lstm(op, (hidden, cell))\n    predictions = self.fc(outputs)\n    # shape of predictions: (1, N, length_of_vocab)\n    predictions = predictions.squeeze(0)\n    # shape of predictions: (N, length_of_vocab)\n    if(self.cell_type == \"LSTM\"):\n        return predictions, hidden, cell\n    return predictions, hidden\n\n","metadata":{"id":"pmqgOzhw0t37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, cell_type, bidirectional, enc_layers, dec_layers):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n#         print(\"seq2seq intilized\")\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n        batch_size = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        if(self.cell_type == \"LSTM\"):\n            encoder_output, hidden, cell = self.encoder(source)\n        else:\n            encoder_output, hidden = self.encoder(source)\n        # if(self.bidirectional == True):\n        if(self.enc_layers != self.dec_layers or self.bidirectional == True):\n          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n          hidden = hidden.repeat(self.dec_layers,1,1)\n          if(self.cell_type == \"LSTM\"):\n              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n              cell = cell.repeat(self.dec_layers,1,1)\n        \n        # Grab the first input to the Decoder which will be <SOS> token\n        x = target[0]\n    \n        for t in range(1, target_len):\n#             print(\"STARTED t= \",t)\n            if(self.cell_type == \"LSTM\"):\n                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n            else :\n                output, hidden = self.decoder(x, encoder_output, hidden)\n#             print(\"output shape = \",output.shape)\n#             print(\"hidden.shape = \", hidden.shape)\n            # Store next output prediction\n            outputs[t] = output\n\n            # Get the best word the Decoder predicted (index in the vocabulary)\n            best_guess = output.argmax(1)\n\n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n#             print(\"x.shape = \",x.shape)\n#             print(\"COMPLETED t \", t)\n            \n#         print(\"decoder sucessful\")\n        return outputs\n","metadata":{"id":"ZkWSEAca-Okj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size):\n    correct_count = 0\n    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n        output = model.forward(inp_data.T, target.T, 0)\n        output = nn.Softmax(dim=2)(output)\n        output = torch.argmax(output, dim=2)\n        \n        output = output.T\n#         print(output[1])\n#         print(output[1][1:])\n#         print(\"output.shape = \",output.shape)\n#         print(\"target.shape = \",target.shape)\n        for i in range(batch_size):\n            if(torch.equal(output[i][1:],target[i][1:])):\n                correct_count += 1\n    accuracy = correct_count * 100 / len(english_matrix)\n    return accuracy\n        ","metadata":{"id":"SYajaq47-xUQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention):\n  learning_rate = 1e-3\n  num_epochs = 20\n  input_size_encoder = len(english_char_list) + 2  # intially= 30 || Now 26 + 1(start token) + 1 = 28 \n  input_size_decoder = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n  output_size        = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n\n  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, enc_layers, enc_dropout, cell_type,bidirectional).to(device)\n  if(attention):\n    decoder_net = Atten_decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type, bidirectional).to(device)\n  else:\n    decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type).to(device)\n\n  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, enc_layers, dec_layers).to(device)\n  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n  pad_idx = len(marathi_char_list) + 1  # 64 # pading index for marathi\n  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n\n\n  for epoch in range(num_epochs):\n      print(\"epoch = \",epoch)\n\n      model.train()\n      total_loss = 0\n      step = 0\n      for batch_idx in range((int)(len(english_matrix) / batch_size)):\n          # Get input and targets and get to cuda\n  #         inp_data = batch.src.to(device)\n  #         target = batch.trg.to(device)\n\n          # Forward prop\n          inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n          target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n  #         inp_data = inp_data.T\n          target = target.T\n          output = model(inp_data.T, target)\n  #         print(\"model successful\")\n  #         print(\"output.shape = \",output.shape)\n\n          output = output[1:].reshape(-1, output.shape[2])\n          target = target[1:].reshape(-1)\n  #         print(\"output.shape = \",output.shape)\n  #         print(\"target.shape = \",target.shape)\n          optimizer.zero_grad()\n          loss = criterion(output, target)\n          total_loss += loss\n          # Back prop\n          loss.backward()\n\n          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n          # Gradient descent step\n          optimizer.step()\n\n          step += 1\n  #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n      print(\"total loss = \",total_loss / step)\n      training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size)\n      print(\"Training Accuracy = \", training_accuracy)\n      val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch, batch_size)\n      print(\"Validation accuracy = \",val_accuracy)\n      test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch, batch_size)\n      print(\"Test accuracy = \", test_accuracy)\n      wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': epoch})\n      if(epoch > 10 and training_accuracy < 10):\n        return\n      if(epoch > 5 and training_accuracy < 1):\n        return","metadata":{"id":"9QCnSmaTMRSR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cell_type = \"RNN\"\n# bidirectional = True\n# enc_layers = 3\n# dec_layers = 2\n# batch_size = 256\n# embedding_size = 384\n# hidden_size = 256\n# dropout = 0.3\n# enc_dropout = 0.3\n# dec_dropout = 0.6\n# attention = True\n\n\n# neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)","metadata":{"id":"jkkdB4_mxLWV","outputId":"d8d86c27-e9b7-42bd-b87e-47e73ab72031"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_NN():\n    \n\n    # Initialize a new wandb run\n    wandb.init()\n    \n    # Config is a variable that holds and saves hyperparameters and inputs\n    config = wandb.config\n\n    # Local variables, values obtained from wandb config\n    \n    cell_type = config.cell_type\n    attention = config.attention\n    bidirectional = config.bidirectional\n    enc_layers = config.enc_layers\n    dec_layers = config.dec_layers\n    batch_size = config.batch_size\n    embedding_size = config.embedding_size\n    hidden_size = config.hidden_size\n    enc_dropout = config.enc_dropout\n    dec_dropout = config.dec_dropout\n\n    # Display the hyperparameters\n    run_name = \"ct_{}_at_{}_bd_{}_enl_{}_dnl_{}_bs_{}_es_{}_hs_{}_edo_{}_ddo_{}\".format(cell_type, attention, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout)\n    print(run_name)\n    neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)\n    wandb.run.name = run_name\n    wandb.run.save()","metadata":{"id":"Hul3BAih-xUR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"-qwOMgXc-xUR"}},{"cell_type":"code","source":"sweep_config = {\n  \"name\": \"CS6910 Assignment 3\",\n  \"metric\": {\n      \"name\":\"validation_accuracy\",\n      \"goal\": \"maximize\"\n  },\n  \"method\": \"bayes\",\n  \"parameters\": {\n        \n       \n        \"cell_type\": {\n            \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n        },\n        \"attention\": {\n            \"values\": [True, False]\n        },\n        \"bidirectional\": {\n            \"values\": [True, False]\n        },\n        \"enc_layers\": {\n            \"values\": [1, 2, 3, 5]\n        },\n        \"dec_layers\": {\n            \"values\": [1, 2, 3, 5]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128, 256]\n        },\n        \"embedding_size\": {\n            \"values\": [16, 32, 64,128, 256, 384, 512]\n        },\n        \"hidden_size\": {\n            \"values\": [16,32,64,128, 256, 384, 512]\n        },\n        \"enc_dropout\": {\n            \"values\": [0,0.2,0.3,0.4,0.6]\n        },\n        \"dec_dropout\": {\n            \"values\": [0,0.2,0.3,0.4,0.6]\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep_config, entity=\"rajmahajan24\", project=\"DL_Assignment_3\")\nwandb.agent(sweep_id, run_NN, count=1200)","metadata":{"id":"pyvrYxCd-xUS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"67svBk48GAaX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"bW22hUA2vTpV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"BMyJeinM-xUS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"d9sr6TtgPdmn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"crRv0WD-Hu6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LyTr7QZKMqQG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1reXcQN1-xUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"mrNT-rKM-xUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"aPoWLZG3-xUT"},"execution_count":null,"outputs":[]}]}