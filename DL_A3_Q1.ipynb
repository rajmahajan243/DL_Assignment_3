{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# DL Assignment 3\n",
        "\n",
        "# version 12.\n",
        "# adding lstm and rnn"
      ],
      "metadata": {
        "id": "FsMRpLJt_egZ",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.083848Z",
          "iopub.execute_input": "2023-05-02T19:28:54.084737Z",
          "iopub.status.idle": "2023-05-02T19:28:54.089684Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.084686Z",
          "shell.execute_reply": "2023-05-02T19:28:54.088455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.230998Z",
          "iopub.execute_input": "2023-05-02T19:28:54.231487Z",
          "iopub.status.idle": "2023-05-02T19:28:54.240212Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.231449Z",
          "shell.execute_reply": "2023-05-02T19:28:54.238900Z"
        },
        "trusted": true,
        "id": "DDghhjha-xUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ADfNyi1sB9L3",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.432238Z",
          "iopub.execute_input": "2023-05-02T19:28:54.433345Z",
          "iopub.status.idle": "2023-05-02T19:28:54.440619Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.433294Z",
          "shell.execute_reply": "2023-05-02T19:28:54.439367Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.568380Z",
          "iopub.execute_input": "2023-05-02T19:28:54.568854Z",
          "iopub.status.idle": "2023-05-02T19:28:54.574983Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.568822Z",
          "shell.execute_reply": "2023-05-02T19:28:54.573856Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeBoqlNt-xUM",
        "outputId": "90290478-f21a-4b3b-e230-dcab7d365168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login(key = \"c28eda24dacbd50a57332e445cfdfb2f4c16799c\")\n",
        "\n",
        "import wandb\n",
        "wandb.init(project=\"DL_A3_Q1_13(without attention)\")"
      ],
      "metadata": {
        "id": "KtCn6lShP54p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "id": "H6Agml7HAllJ",
        "outputId": "e05d30b5-5e69-4a78-df34-548bebfd9f2e",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.789177Z",
          "iopub.execute_input": "2023-05-02T19:28:54.790066Z",
          "iopub.status.idle": "2023-05-02T19:28:54.794504Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.790021Z",
          "shell.execute_reply": "2023-05-02T19:28:54.793220Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# path = '/kaggle/input/marathi/mar_train.csv'\n",
        "# path_val = '/kaggle/input/marathi/mar_valid.csv'\n",
        "# path_test = '/kaggle/input/marathi/mar_test.csv'\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv'\n",
        "path_val = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv'\n",
        "path_test = '/content/drive/MyDrive/Colab Notebooks/DL Assignment/Assignment 3/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv'"
      ],
      "metadata": {
        "id": "299AqvvaEdkf",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:54.983768Z",
          "iopub.execute_input": "2023-05-02T19:28:54.985064Z",
          "iopub.status.idle": "2023-05-02T19:28:54.990689Z",
          "shell.execute_reply.started": "2023-05-02T19:28:54.985011Z",
          "shell.execute_reply": "2023-05-02T19:28:54.989488Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path , header = None)\n",
        "# df.head()\n",
        "df_val = pd.read_csv(path_val , header = None)\n",
        "df_test = pd.read_csv(path_test , header = None)\n",
        "english_words_val = df_val[0]\n",
        "marathi_words_val = df_val[1]\n",
        "english_words_test = df_test[0]\n",
        "marathi_words_test = df_test[1]\n",
        "english_words = df[0]\n",
        "marathi_words = df[1]\n",
        "# print(english_words)\n",
        "# print(marathi_words)\n",
        "print(df[50000:])"
      ],
      "metadata": {
        "id": "NtpQ9UGxFhkU",
        "outputId": "d4ff3b2d-9094-4b59-b169-fbe12051ccc1",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:55.276050Z",
          "iopub.execute_input": "2023-05-02T19:28:55.276574Z",
          "iopub.status.idle": "2023-05-02T19:28:55.466767Z",
          "shell.execute_reply.started": "2023-05-02T19:28:55.276540Z",
          "shell.execute_reply": "2023-05-02T19:28:55.465298Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         0                 1\n",
            "50000  audhogikikaranamule   औधोगिकीकरणामुळे\n",
            "50001     anyayaviruddhahi  अन्यायाविरुद्धही\n",
            "50002              fairade            फैराडे\n",
            "50003          inputmadhye        इनपुटमध्ये\n",
            "50004      charitranmadhil      चरित्रांमधील\n",
            "...                    ...               ...\n",
            "51195           chikateche           चिकटेचे\n",
            "51196     anubhavanyachahi     अनुभवण्याचाही\n",
            "51197            andhapuri          अंधापुरी\n",
            "51198           ghadamodee           घडामोडी\n",
            "51199         atiprachalit        अतिप्रचलित\n",
            "\n",
            "[1200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating list of charecters in both languages\n",
        "\n",
        "english_char_list = []\n",
        "max_length_word_english = -1\n",
        "for word in english_words:\n",
        "  max_length_word_english = max(max_length_word_english,len(word)) \n",
        "  for char in word :\n",
        "    english_char_list.append(char);\n",
        "english_char_list = list(set(english_char_list))\n",
        "english_char_list.sort()\n",
        "# print(len(english_char_list))\n",
        "print(english_char_list)\n",
        "# print(max_length_word_english)\n",
        "\n",
        "marathi_char_list = []\n",
        "max_length_word_marathi = -1\n",
        "for word in marathi_words:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
        "  for char in word :\n",
        "    marathi_char_list.append(char);\n",
        "marathi_char_list = list(set(marathi_char_list))\n",
        "marathi_char_list.sort()\n",
        "# print(len(marathi_char_list))\n",
        "print(marathi_char_list)\n",
        "\n",
        "\n",
        "# finding out the maximum size word for english and marathi from validation and test data.\n",
        "for word in english_words_val:\n",
        "  max_length_word_english = max(max_length_word_english,len(word))\n",
        "for word in english_words_test:\n",
        "  max_length_word_english = max(max_length_word_english,len(word)) \n",
        "for word in marathi_words_val:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
        "for word in marathi_words_test:\n",
        "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
        "\n",
        "print(max_length_word_english)\n",
        "print(max_length_word_marathi)"
      ],
      "metadata": {
        "id": "mtlfObKubBNq",
        "outputId": "2c5a9a23-1af2-4d79-917e-ca1de4cd0661",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:55.524358Z",
          "iopub.execute_input": "2023-05-02T19:28:55.525445Z",
          "iopub.status.idle": "2023-05-02T19:28:55.817261Z",
          "shell.execute_reply.started": "2023-05-02T19:28:55.525399Z",
          "shell.execute_reply": "2023-05-02T19:28:55.816166Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऍ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
            "28\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english word to vector size = 27 ie. max_length_word_english\n",
        "# marathi word to vector size = 20 ie. max_length_word_marathi\n",
        "# for one word.\n",
        "def word2vec(word, lang):\n",
        "  vec = []\n",
        "  if(lang == \"english\"):\n",
        "    vec.append(len(english_char_list) + 1)\n",
        "    for char in word:\n",
        "      for i in range(len(english_char_list)):\n",
        "        if(english_char_list[i] == char):\n",
        "          vec.append(i+1)\n",
        "    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n",
        "#         vec.append(len(english_char_list) + 2)\n",
        "        vec.append(0)\n",
        "#     vec.append(len(english_char_list) + 2)\n",
        "    vec.append(0)\n",
        "  else :\n",
        "    vec.append(len(marathi_char_list) + 1)\n",
        "    for char in word:\n",
        "      for i in range(len(marathi_char_list)):\n",
        "        if( marathi_char_list[i] == char):\n",
        "          vec.append(i+1)\n",
        "    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n",
        "#         vec.append(len(marathi_char_list) + 2)\n",
        "        vec.append(0)\n",
        "#     vec.append(len(marathi_char_list) + 2)\n",
        "    vec.append(0)\n",
        "  return(vec)\n"
      ],
      "metadata": {
        "id": "fdcqBaU70W3v",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:55.818982Z",
          "iopub.execute_input": "2023-05-02T19:28:55.819320Z",
          "iopub.status.idle": "2023-05-02T19:28:55.828375Z",
          "shell.execute_reply.started": "2023-05-02T19:28:55.819292Z",
          "shell.execute_reply": "2023-05-02T19:28:55.826970Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec = word2vec(marathi_words[10],\"marathi\")\n",
        "print(marathi_words[10])\n",
        "print(vec)"
      ],
      "metadata": {
        "id": "heu_03Y3332P",
        "outputId": "a5e27a9b-2b02-472a-989b-26c36de5cb72",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:55.963495Z",
          "iopub.execute_input": "2023-05-02T19:28:55.964042Z",
          "iopub.status.idle": "2023-05-02T19:28:55.973354Z",
          "shell.execute_reply.started": "2023-05-02T19:28:55.963999Z",
          "shell.execute_reply": "2023-05-02T19:28:55.972048Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "हरिहरक्षेत्र\n",
            "[64, 49, 42, 52, 49, 42, 17, 63, 47, 58, 31, 63, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating matrix of representation for whole words of english and marathi.\n",
        "\n",
        "def ip_matrix_construct(words, lang):\n",
        "  ans = []\n",
        "  for word in words:\n",
        "    ans.append(word2vec(word, lang))\n",
        "  return(ans)"
      ],
      "metadata": {
        "id": "pRObgwk5pcEz",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:56.204249Z",
          "iopub.execute_input": "2023-05-02T19:28:56.204734Z",
          "iopub.status.idle": "2023-05-02T19:28:56.210713Z",
          "shell.execute_reply.started": "2023-05-02T19:28:56.204696Z",
          "shell.execute_reply": "2023-05-02T19:28:56.208966Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculated representations of whole english and marathi words in variables english and marathi matrix.\n",
        "english_matrix = ip_matrix_construct(english_words, \"english\")\n",
        "marathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n",
        "# english_matrix = english_matrix[:100]\n",
        "# marathi_matrix = marathi_matrix[:100]\n",
        "print(len(english_matrix))\n",
        "print(len(marathi_matrix))\n",
        "english_matrix = torch.tensor(english_matrix)\n",
        "marathi_matrix = torch.tensor(marathi_matrix)\n",
        "print(len(english_matrix[0]))\n",
        "print(len(marathi_matrix[0]))\n",
        "\n",
        "english_matrix_val = ip_matrix_construct(english_words_val, \"english\")\n",
        "marathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\n",
        "english_matrix_val = torch.tensor(english_matrix_val)\n",
        "marathi_matrix_val = torch.tensor(marathi_matrix_val)\n",
        "english_matrix_test = ip_matrix_construct(english_words_test, \"english\")\n",
        "marathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\n",
        "english_matrix_test = torch.tensor(english_matrix_test)\n",
        "marathi_matrix_test = torch.tensor(marathi_matrix_test)"
      ],
      "metadata": {
        "id": "1FgS76C6rluA",
        "outputId": "cd5ed0f1-f143-4898-883d-d5a5e031f755",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:28:56.615067Z",
          "iopub.execute_input": "2023-05-02T19:28:56.615500Z",
          "iopub.status.idle": "2023-05-02T19:29:02.927630Z",
          "shell.execute_reply.started": "2023-05-02T19:28:56.615471Z",
          "shell.execute_reply": "2023-05-02T19:29:02.925051Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51200\n",
            "51200\n",
            "30\n",
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alaadin\n",
        "# input size = number of characters in lang eg, english = 26 + 1 for start of sentence + 1 for end of sentence.\n",
        "# embedding size  = hyperparamter\n",
        "# hidden size = hyperparametrv \n",
        "# num layers  = hyperparametr\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size, embedding_size, hidden_size, num_layers, p, cell_type):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if(cell_type == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout = p, bidirectional = True)\n",
        "    if(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout = p, bidirectional = True)\n",
        "    if(cell_type == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p, bidirectional = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x shape: (seq_length, N)  where N is batch size\n",
        "#     print(\"shape of x\")\n",
        "#     print(x.shape)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "#     print(\"shape of embedding\")\n",
        "#     print(embedding.shape)\n",
        "    # embedding shape : (seq_length, N, embedding_size)\n",
        "    if(self.cell_type == \"GRU\"):\n",
        "      output, hidden = self.gru(embedding)\n",
        "    if(self.cell_type == \"RNN\"):\n",
        "      output, hidden = self.rnn(embedding)\n",
        "    if(self.cell_type == \"LSTM\"):\n",
        "      outputs, (hidden,cell) = self.lstm(embedding)\n",
        "      # print(\"hidden.shape\",hidden.shape)\n",
        "      # print(\"cell.shape\",cell.shape)\n",
        "      return hidden, cell\n",
        "    # print(\"output.shape\",output.shape)\n",
        "    # print(\"hidden.shape\",hidden.shape)\n",
        "#     print(output.size())\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "cvjQGsLrsBJZ",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:29:02.929628Z",
          "iopub.status.idle": "2023-05-02T19:29:02.930305Z",
          "shell.execute_reply.started": "2023-05-02T19:29:02.929995Z",
          "shell.execute_reply": "2023-05-02T19:29:02.930026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alaadin\n",
        "# input size = number of characters for target lang eg, marathi = 63\n",
        "# embedidng size = will be sae as above.\n",
        "# hidden size = same as above\n",
        "# output size = same as input size ie. number of characters for target lang eg, marathi = 63\n",
        "# num layers = same as above\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p, cell_type):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    if(cell_type == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    if(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    if(cell_type == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size, cell_type)  # fully connected.\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "    # shape of x: (N) but we want (1,N)\n",
        "    x = x.unsqueeze(0).int()\n",
        "#     print(\"shape of x\")\n",
        "#     print(x.shape)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedding shape : (1,N,embedding_size)\n",
        "#     print(\"embedding shape\")\n",
        "#     print(embedding.shape)\n",
        "    if(self.cell_type == \"GRU\"):\n",
        "      outputs, hidden = self.gru(embedding, hidden)\n",
        "    if(self.cell_type == \"RNN\"):\n",
        "      outputs, hidden = self.rnn(embedding, hidden)\n",
        "\n",
        "    # shape of outputs: (1, N, hidden_size)\n",
        "    predictions = self.fc(outputs)\n",
        "    # shape of predictions: (1, N, length_of_vocab)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    # shape of predictions: (N, length_of_vocab)\n",
        "    return predictions, hidden\n",
        "\n",
        "  def forward(self, x, hidden, cell): # for LSTM\n",
        "    # shape of x: (N) but we want (1,N)\n",
        "    x = x.unsqueeze(0).int()\n",
        "#     print(\"shape of x\")\n",
        "#     print(x.shape)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedding shape : (1,N,embedding_size)\n",
        "    outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "\n",
        "    # shape of outputs: (1, N, hidden_size)\n",
        "    predictions = self.fc(outputs)\n",
        "    # shape of predictions: (1, N, length_of_vocab)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    # shape of predictions: (N, length_of_vocab)\n",
        "    return predictions, hidden, cell\n",
        "\n",
        "  def initHidden(self):\n",
        "#     print(\"init hidden decoder\")\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-02T19:29:02.931907Z",
          "iopub.status.idle": "2023-05-02T19:29:02.932414Z",
          "shell.execute_reply.started": "2023-05-02T19:29:02.932191Z",
          "shell.execute_reply": "2023-05-02T19:29:02.932212Z"
        },
        "trusted": true,
        "id": "nea9Nz5E-xUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "#         print(\"seq2seq intilized\")\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "#         print(\"seq2seq forward started\")\n",
        "#         source = source.T\n",
        "#         target = target.T\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "#         print(batch_size)\n",
        "#         print(target_len)\n",
        "#         print(source.shape)\n",
        "#         print(target.shape)\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "        if(cell_type == \"LSTM\"):\n",
        "          hidden, cell = self.encoder(source)\n",
        "        else:\n",
        "          output, hidden = self.encoder(source)\n",
        "        # print(\"encoder succesful\")\n",
        "        # print(\"shape of hidden\")\n",
        "#         print(\"shape of output\")\n",
        "        # print(hidden.shape)\n",
        "        if(bidirectional == True):\n",
        "          hidden = hidden[num_layers - 1] + hidden[num_layers - 1]\n",
        "          hidden = hidden.repeat(num_layers,1,1)\n",
        "          if(cell_type == \"LSTM\"):\n",
        "            cell = cell[num_layers - 1] + cell[num_layers - 1]\n",
        "            cell = cell.repeat(num_layers,1,1)\n",
        "        # print(hidden.shape)\n",
        "        # Grab the first input to the Decoder which will be <SOS> token\n",
        "        x = target[0]\n",
        "    \n",
        "        for t in range(1, target_len):\n",
        "#             print(\"STARTED t= \",t)\n",
        "            if(cell_type == \"LSTM\"):\n",
        "              output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            else :\n",
        "              output, hidden = self.decoder(x, hidden)\n",
        "#             print(\"output shape = \",output.shape)\n",
        "#             print(\"hidden.shape = \", hidden.shape)\n",
        "            # Store next output prediction\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "            best_guess = output.argmax(1)\n",
        "\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "#             print(\"x.shape = \",x.shape)\n",
        "#             print(\"COMPLETED t \", t)\n",
        "            \n",
        "#         print(\"decoder sucessful\")\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "ZkWSEAca-Okj",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:29:02.934133Z",
          "iopub.status.idle": "2023-05-02T19:29:02.934747Z",
          "shell.execute_reply.started": "2023-05-02T19:29:02.934457Z",
          "shell.execute_reply": "2023-05-02T19:29:02.934484Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(model, english_matrix, marathi_matrix, epoch):\n",
        "    correct_count = 0\n",
        "    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        output = model.forward(inp_data.T, target.T, 0)\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        \n",
        "        output = output.T\n",
        "#         print(output[1])\n",
        "#         print(output[1][1:])\n",
        "#         print(\"output.shape = \",output.shape)\n",
        "#         print(\"target.shape = \",target.shape)\n",
        "        for i in range(batch_size):\n",
        "            if(torch.equal(output[i][1:],target[i][1:])):\n",
        "                correct_count += 1\n",
        "    accuracy = correct_count * 100 / len(english_matrix)\n",
        "    return accuracy\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-02T19:29:02.938793Z",
          "iopub.status.idle": "2023-05-02T19:29:02.939411Z",
          "shell.execute_reply.started": "2023-05-02T19:29:02.939137Z",
          "shell.execute_reply": "2023-05-02T19:29:02.939163Z"
        },
        "trusted": true,
        "id": "SYajaq47-xUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### We're ready to define everything we need for training our Seq2Seq model ###\n",
        "\n",
        "# # Training hyperparameters\n",
        "# num_epochs = 1000\n",
        "# learning_rate = 0.001\n",
        "# batch_size = 32\n",
        "\n",
        "# # Model hyperparameters\n",
        "# load_model = False\n",
        "# input_size_encoder = len(english_char_list) + 2  # intially= 30 || Now 26 + 1(start token) + 1 = 28 \n",
        "# input_size_decoder = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "# output_size        = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "# encoder_embedding_size = 256\n",
        "# decoder_embedding_size = 256\n",
        "# hidden_size = 256  # Needs to be the same for both RNN's\n",
        "# num_layers = 2\n",
        "# enc_dropout = 0.5\n",
        "# dec_dropout = 0.5\n",
        "# cell_type = \"LSTM\"\n",
        "# bidirectional = True\n",
        "\n",
        "\n",
        "# encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout, cell_type).to(device)\n",
        "\n",
        "# decoder_net = Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size,num_layers,dec_dropout, cell_type).to(device)\n",
        "\n",
        "# model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# pad_idx = 65 # pading index for marathi\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "# # if load_model:\n",
        "# #     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
        "\n",
        "\n",
        "# # sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     print(\"epoch = \",epoch)\n",
        "\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "#     step = 0\n",
        "#     for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "#         # Get input and targets and get to cuda\n",
        "# #         inp_data = batch.src.to(device)\n",
        "# #         target = batch.trg.to(device)\n",
        "\n",
        "#         # Forward prop\n",
        "#         inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "#         target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "# #         inp_data = inp_data.T\n",
        "#         target = target.T\n",
        "#         output = model(inp_data.T, target)\n",
        "# #         print(\"model successful\")\n",
        "# #         print(\"output.shape = \",output.shape)\n",
        "\n",
        "#         output = output[1:].reshape(-1, output.shape[2])\n",
        "#         target = target[1:].reshape(-1)\n",
        "# #         print(\"output.shape = \",output.shape)\n",
        "# #         print(\"target.shape = \",target.shape)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss = criterion(output, target)\n",
        "#         total_loss += loss\n",
        "#         # Back prop\n",
        "#         loss.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "#         # Gradient descent step\n",
        "#         optimizer.step()\n",
        "\n",
        "#         step += 1\n",
        "# #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n",
        "#     print(\"total loss = \",total_loss / step)\n",
        "#     training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch)\n",
        "#     print(\"Training Accuracy = \", training_accuracy)\n",
        "#     val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch)\n",
        "#     print(\"Validation accuracy = \",val_accuracy)\n",
        "#     test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch)\n",
        "#     print(\"Test accuracy = \", test_accuracy)\n",
        "    \n"
      ],
      "metadata": {
        "id": "J4uy60ImBlin",
        "execution": {
          "iopub.status.busy": "2023-05-02T19:29:02.941590Z",
          "iopub.status.idle": "2023-05-02T19:29:02.942215Z",
          "shell.execute_reply.started": "2023-05-02T19:29:02.941910Z",
          "shell.execute_reply": "2023-05-02T19:29:02.941938Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb1d764-dd14-4acf-cfa7-842f98c61535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  0\n",
            "total loss =  tensor(0.7925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  10.4140625\n",
            "Validation accuracy =  13.3544921875\n",
            "Test accuracy =  11.1572265625\n",
            "epoch =  1\n",
            "total loss =  tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  18.76953125\n",
            "Validation accuracy =  20.849609375\n",
            "Test accuracy =  16.9921875\n",
            "epoch =  2\n",
            "total loss =  tensor(0.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  23.755859375\n",
            "Validation accuracy =  24.90234375\n",
            "Test accuracy =  21.8505859375\n",
            "epoch =  3\n",
            "total loss =  tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  27.876953125\n",
            "Validation accuracy =  27.2216796875\n",
            "Test accuracy =  24.3896484375\n",
            "epoch =  4\n",
            "total loss =  tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  30.744140625\n",
            "Validation accuracy =  29.2236328125\n",
            "Test accuracy =  25.9521484375\n",
            "epoch =  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout):\n",
        "  num_epochs = 15\n",
        "  learning_rate = 0.001\n",
        "  input_size_encoder = len(english_char_list) + 2  # intially= 30 || Now 26 + 1(start token) + 1 = 28 \n",
        "  input_size_decoder = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "  output_size        = len(marathi_char_list) + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "\n",
        "  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, num_layers, dropout, cell_type).to(device)\n",
        "\n",
        "  decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,num_layers,dropout, cell_type).to(device)\n",
        "\n",
        "  model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  pad_idx = 65 # pading index for marathi\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "  # if load_model:\n",
        "  #     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
        "\n",
        "\n",
        "  # sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(\"epoch = \",epoch)\n",
        "\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      step = 0\n",
        "      for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
        "          # Get input and targets and get to cuda\n",
        "  #         inp_data = batch.src.to(device)\n",
        "  #         target = batch.trg.to(device)\n",
        "\n",
        "          # Forward prop\n",
        "          inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "          target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "  #         inp_data = inp_data.T\n",
        "          target = target.T\n",
        "          output = model(inp_data.T, target)\n",
        "  #         print(\"model successful\")\n",
        "  #         print(\"output.shape = \",output.shape)\n",
        "\n",
        "          output = output[1:].reshape(-1, output.shape[2])\n",
        "          target = target[1:].reshape(-1)\n",
        "  #         print(\"output.shape = \",output.shape)\n",
        "  #         print(\"target.shape = \",target.shape)\n",
        "          optimizer.zero_grad()\n",
        "          loss = criterion(output, target)\n",
        "          total_loss += loss\n",
        "          # Back prop\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "          # Gradient descent step\n",
        "          optimizer.step()\n",
        "\n",
        "          step += 1\n",
        "  #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n",
        "      print(\"total loss = \",total_loss / step)\n",
        "      training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch)\n",
        "      print(\"Training Accuracy = \", training_accuracy)\n",
        "      val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch)\n",
        "      print(\"Validation accuracy = \",val_accuracy)\n",
        "      # test_accuracy = Accuracy(model, english_matrix_test, marathi_matrix_test, epoch)\n",
        "      # print(\"Test accuracy = \", test_accuracy)\n",
        "      wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': epoch})"
      ],
      "metadata": {
        "id": "9QCnSmaTMRSR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_NN():\n",
        "    \n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init()\n",
        "    \n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    # Local variables, values obtained from wandb config\n",
        "    cell_type = config.cell_type\n",
        "    bidirectional = config.bidirectional\n",
        "    num_layers = config.num_layers\n",
        "    batch_size = config.batch_size\n",
        "    embedding_size = config.embedding_size\n",
        "    hidden_size = config.hidden_size\n",
        "    dropout = config.dropout\n",
        "\n",
        "    # Display the hyperparameters\n",
        "    run_name = \"ct_{}_bd_{}_nl_{}_bs_{}_es_{}_hs_{}_do_{}\".format(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout)\n",
        "    print(run_name)\n",
        "    neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout)\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()"
      ],
      "metadata": {
        "id": "Hul3BAih-xUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-qwOMgXc-xUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "  \"name\": \"CS6910 Assignment 3\",\n",
        "  \"metric\": {\n",
        "      \"name\":\"validation_accuracy\",\n",
        "      \"goal\": \"maximize\"\n",
        "  },\n",
        "  \"method\": \"random\",\n",
        "  \"parameters\": {\n",
        "        \n",
        "        \"cell_type\": {\n",
        "            \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n",
        "        },\n",
        "        \"bidirectional\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "        \"num_layers\": {\n",
        "            \"values\": [1, 2, 3]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [32,64,128]\n",
        "        },\n",
        "        \"embedding_size\": {\n",
        "            \"values\": [16, 32, 64, 256]\n",
        "        },\n",
        "        \"hidden_size\": {\n",
        "            \"values\": [16,32,64,256]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.2,0.3]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"rajmahajan24\", project=\"DL_A3_Q1_13(without attention)\")\n",
        "wandb.agent(sweep_id, run_NN, count=1200)"
      ],
      "metadata": {
        "id": "pyvrYxCd-xUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "67svBk48GAaX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bW22hUA2vTpV",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "BMyJeinM-xUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9sr6TtgPdmn",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crRv0WD-Hu6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyTr7QZKMqQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1reXcQN1-xUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrNT-rKM-xUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPoWLZG3-xUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
